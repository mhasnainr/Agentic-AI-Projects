{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhasnainr/Agentic-AI-Projects/blob/main/quickstarts/Function_calling_config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDS9Xcj_8k-T"
      },
      "source": [
        "# Gemini API: Function calling config\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb\"><img src=\"https://github.com/google-gemini/cookbook/blob/main/images/colab_logo_32px.png?raw=1\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e41a2ce62eb"
      },
      "source": [
        "Specifying a `function_calling_config` allows you to control how the Gemini API acts when `tools` have been specified. For example, you can choose to only allow free-text output (disabling function calling), force it to choose from a subset of the functions provided in `tools`, or let it act automatically.\n",
        "\n",
        "This guide assumes you are already familiar with function calling. For an introduction, check out the [docs](https://ai.google.dev/docs/function_calling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m4DhA4907Asz"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU-mY9hi8pQh"
      },
      "source": [
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wp3W4Pdf8rBO"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJqil-VL8ug-"
      },
      "source": [
        "## Set up a model with tools\n",
        "\n",
        "This example uses 3 functions that control a simple hypothetical lighting system. Using these functions requires them to be called in a specific order. For example, you must turn the light system on before you can change color.\n",
        "\n",
        "While you can pass these directly to the model and let it try to call them correctly, specifying the `function_calling_config` gives you precise control over the functions that are available to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gLS26n7A9l9B"
      },
      "outputs": [],
      "source": [
        "def enable_lights():\n",
        "    \"\"\"Turn on the lighting system.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights enabled.\")\n",
        "\n",
        "\n",
        "def set_light_color(rgb_hex: str):\n",
        "    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"\n",
        "    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n",
        "\n",
        "\n",
        "def stop_lights():\n",
        "    \"\"\"Stop flashing lights.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights turned off.\")\n",
        "\n",
        "def find_batch():\n",
        "    \"\"\"Enter roll number from 1-50: \"\"\"\n",
        "    print(\"Batch number: \")\n",
        "\n",
        "\n",
        "light_controls = [enable_lights, set_light_color, stop_lights, find_batch]\n",
        "instruction = \"You are a helpful lighting system bot. You can turn lights on and off, and you can set the color and find batch number after receiving the roll number. Do not perform any other tasks.\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\", tools=light_controls, system_instruction=instruction\n",
        ")\n",
        "\n",
        "chat = model.start_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqROCznFCj_Y"
      },
      "source": [
        "Create a helper function for setting `function_calling_config` on `tool_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_QgLFPL4Chon"
      },
      "outputs": [],
      "source": [
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMEuh_MFdMf"
      },
      "source": [
        "## Text-only mode: `NONE`\n",
        "\n",
        "If you have provided the model with tools, but do not want to use those tools for the current conversational turn, then specify `NONE` as the mode. `NONE` tells the model not to make any function calls, and will behave as though none have been provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6ZlIFwXqGA09",
        "outputId": "bfdb7187-5d65-4824-e8cd-968d93afd6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can turn lights on and off, set the color of lights, and find the batch number after receiving the roll number.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hello light-bot, what can you do?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uux063sjHZ_Z"
      },
      "source": [
        "## Automatic mode: `AUTO`\n",
        "\n",
        "To allow the model to decide whether to respond in text or call specific functions, you can specify `AUTO` as the mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vwO9dUjvHoT8",
        "outputId": "a42d2163-2263-46f7-8b47-f0b40a9e4d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"enable_lights\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "\n",
        "response = chat.send_message(\"Light this place up!\", tool_config=tool_config)\n",
        "print(response.parts[0])\n",
        "chat.rewind();  # You are not actually calling the function, so remove this from the history."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHhaO-P9CBPb"
      },
      "source": [
        "## Function-calling mode: `ANY`\n",
        "\n",
        "Setting the mode to `ANY` will force the model to make a function call. By setting `allowed_function_names`, the model will only choose from those functions. If it is not set, all of the functions in `tools` are candidates for function calling.\n",
        "\n",
        "In this example system, if the lights are already on, then the user can change color or turn the lights off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GQpz94zrCNJF",
        "outputId": "756c9294-4956-4d27-fdfe-6c87bf0d7c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"set_light_color\"\n",
            "  args {\n",
            "    fields {\n",
            "      key: \"rgb_hex\"\n",
            "      value {\n",
            "        string_value: \"FF00FF\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "available_fns = [\"set_light_color\", \"stop_lights\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Make this place PURPLE!\", tool_config=tool_config)\n",
        "print(response.parts[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"find_batch\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Show roll number of the student\", tool_config=tool_config)\n",
        "print(response.parts[0])"
      ],
      "metadata": {
        "id": "qYsamVpZY5MK",
        "outputId": "6847eabe-e76e-4bd6-efe2-b24dbacfc097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"find_batch\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cGrRy-uJ7-J"
      },
      "source": [
        "## Automatic function calling\n",
        "\n",
        "`tool_config` works when enabling automatic function calling too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hx7aIX8OXvi6",
        "outputId": "411e12ef-f02f-4021-f8a1-f8dd43bf79d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights enabled.\n",
            "LIGHTBOT: Lights set to #FFFF00.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"OK. I've set the light color to yellow. Anything else?\\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"avg_logprobs\": -0.006441272795200348\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 203,\n",
              "        \"candidates_token_count\": 16,\n",
              "        \"total_token_count\": 219\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "available_fns = [\"enable_lights\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "auto_chat.send_message(\"set yellow color\", tool_config=tool_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz8McBZfXg0N"
      },
      "source": [
        "## Further reading\n",
        "\n",
        "Check out the function calling [quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb) for an introduction to function calling. You can find another fun function calling example [here](https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb) using curl.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_light_values(brightness: int, color_temp: str):\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"brightness\": brightness,\n",
        "        \"colorTemperature\": color_temp\n",
        "    }\n",
        "\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
        "                              tools=[set_light_values])"
      ],
      "metadata": {
        "id": "2WHVk7QaazTQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
        "                              tools=[set_light_values])"
      ],
      "metadata": {
        "id": "iQgh5-5gaz2E"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()\n",
        "response = chat.send_message('Dim the lights so the room feels cozy and warm.')\n",
        "response"
      ],
      "metadata": {
        "id": "-333ekrZa7xl",
        "outputId": "561fe1dc-f26f-4cba-fae0-0faec084bf7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"function_call\": {\n",
              "                  \"name\": \"set_light_values\",\n",
              "                  \"args\": {\n",
              "                    \"brightness\": 30.0,\n",
              "                    \"color_temp\": \"warm\"\n",
              "                  }\n",
              "                }\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"avg_logprobs\": -0.0010158222168684006\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 150,\n",
              "        \"candidates_token_count\": 10,\n",
              "        \"total_token_count\": 160\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a chat session that automatically makes suggested function calls\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "response = chat.send_message('Dim the lights so the room feels cozy and warm.')\n",
        "response.text"
      ],
      "metadata": {
        "id": "qAKpCryxa9ur",
        "outputId": "c48a61ed-115d-4793-f3e9-d9e35c764835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"OK. I've dimmed the lights to 30% brightness and set the color temperature to warm.  Is there anything else?\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def power_disco_ball(power: bool) -> bool:\n",
        "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
        "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "      energetic: Whether the music is energetic or not.\n",
        "      loud: Whether the music is loud or not.\n",
        "      bpm: The beats per minute of the music.\n",
        "\n",
        "    Returns: The name of the song being played.\n",
        "    \"\"\"\n",
        "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
        "    return \"Never gonna give you up.\"\n",
        "\n",
        "\n",
        "def dim_lights(brightness: float) -> bool:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "    \"\"\"\n",
        "    print(f\"Lights are now set to {brightness:.0%}\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "lW2S1oNpckLs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model up with tools.\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
        "\n",
        "# Call the API.\n",
        "chat = model.start_chat()\n",
        "response = chat.send_message(\"Turn this place into a party!\")\n",
        "\n",
        "# Print out each of the function calls requested from this single call.\n",
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "id": "Mf1YewxmdPz7",
        "outputId": "0c54a7c3-3f13-4052-ac97-51de9f1ac50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "power_disco_ball(power=True)\n",
            "start_music(loud=True, energetic=True, bpm=120.0)\n",
            "dim_lights(brightness=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model up with tools.\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
        "\n",
        "# Call the API.\n",
        "chat = model.start_chat()\n",
        "response = chat.send_message(\"Turn this place into a party!\")"
      ],
      "metadata": {
        "id": "TvYLMTBMdUdY",
        "outputId": "05b4d6fb-f7b7-4101-9b22-8fa656f03795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Party started!  Never gonna give you up is now playing. The disco ball is spinning and the lights are dimmed to 50% brightness.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode.tools.to_proto()"
      ],
      "metadata": {
        "id": "fYbD739Odfuv",
        "outputId": "0cedec9b-3199-48bb-cd10-f0f5a480bd0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mode' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-235a9ae81429>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eFWjcahNeT5R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Function_calling_config.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}